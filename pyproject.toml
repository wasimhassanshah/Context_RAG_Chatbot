[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "contextual-rag-chatbot"
version = "0.1.0"
description = "Advanced Contextual RAG Chatbot with Docling, LlamaIndex, PostgreSQL, and Ollama"
authors = [
    {name = "Your Name", email = "your.email@example.com"},
]
readme = "README.md"
requires-python = ">=3.12"
license = {text = "MIT"}
keywords = ["rag", "chatbot", "llm", "contextual", "ai"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.12",
]

dependencies = [
    # Core Framework
    "python-dotenv>=1.0.0",
    "pydantic>=2.5.0",
    # Document Processing - Docling Data Pipeline
    "docling>=1.14.0",
    "docling-core>=1.5.0",
    "docling-ibm-models>=1.0.4",
    "docling-parse>=1.9.0",
    # LlamaIndex + PGVector/PostgreSQL RAG
    "llama-index>=0.10.0",
    "llama-index-core>=0.10.0",
    "llama-index-embeddings-ollama>=0.1.0",
    "llama-index-llms-ollama>=0.1.0",
    "llama-index-vector-stores-postgres>=0.1.0",
    "llama-index-postprocessor-cohere-rerank>=0.1.0",
    # PostgreSQL + PGVector Database
    "psycopg2-binary>=2.9.9",
    "pgvector>=0.2.4",
    "sqlalchemy>=2.0.0",
    "asyncpg>=0.29.0",
    # Locally hosted models via Ollama
    "ollama>=0.2.0",
    # Crew.AI Agentic Framework & Prompt Optimization
    "crewai>=0.28.0",
    "crewai-tools>=0.4.0",
    "langchain>=0.1.0",
    "langchain-community>=0.0.20",
    "langchain-core>=0.1.0",
    # RAGAs LLMOps (Tracing & Debugging)
    "ragas>=0.1.0",
    # Arize Phoenix (Prompt Playground + Chatbot Interface + Evaluation)
    "arize-phoenix>=3.0.0",
    "openinference-instrumentation>=0.1.0",
    "openinference-instrumentation-llama-index>=1.0.0",
    # Open WebUI Integration
    "fastapi>=0.104.0",
    "uvicorn>=0.24.0",
    "requests>=2.31.0",
    # Essential Utilities
    "numpy>=1.24.0",
    "pandas>=2.0.0",
    "tqdm>=4.66.0",
    "datasets>=4.0.0",
    "langchain-ollama>=0.3.6",
    "langchain-groq>=0.3.7",
    "websockets>=15.0.1",
    "jinja2>=3.1.6",
    "openinference-instrumentation-langchain>=0.1.50",
    "opentelemetry-api>=1.36.0",
    "opentelemetry-sdk>=1.36.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "black>=23.0.0",
    "isort>=5.12.0",
]

all = [
    "contextual-rag-chatbot[dev]"
]

[project.urls]
Homepage = "https://github.com/yourusername/contextual-rag-chatbot"
Repository = "https://github.com/yourusername/contextual-rag-chatbot"
Issues = "https://github.com/yourusername/contextual-rag-chatbot/issues"

[project.scripts]
rag-chat = "contextual_rag.main:app"
rag-setup = "contextual_rag.setup:setup_command"

[tool.hatch.build.targets.wheel]
packages = ["src/contextual_rag"]

[tool.hatch.build.targets.sdist]
include = [
    "/src",
    "/tests",
    "/docs",
    "/README.md",
    "/LICENSE",
]

[tool.black]
line-length = 88
target-version = ['py310']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88
known_first_party = ["contextual_rag"]

[tool.mypy]
python_version = "3.12"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
addopts = [
    "--strict-markers",
    "--strict-config",
    "--verbose",
]
markers = [
    "slow: marks tests as slow",
    "integration: marks tests as integration tests",
    "unit: marks tests as unit tests",
]

[tool.coverage.run]
source = ["src"]
omit = [
    "*/tests/*",
    "*/test_*",
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError",
]
